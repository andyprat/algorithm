{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwwuTXO59NOWZM74J+Nk3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andyprat/algorithm/blob/master/R1_02v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zroWW5S53uMu"
      },
      "outputs": [],
      "source": [
        "# keras LSTM neural network\n",
        "## raw version\n",
        "## org ==> _v6py_files/Aug17/ 28 August 2023\n",
        "## model based on DL with py, Francois Chollet\n",
        "##  https://www.manning.com/books/deep-learning-with-python-second-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##     -------  data param  -------------\n",
        "\n",
        "## print(df.shape)\n",
        "## data.info()\n",
        "## df.describe()  -->count, mean, standard deviation, minimum,\n",
        "##                   maximum values and the quantiles of the data\n",
        "## design:\n",
        "## 1) Data preparation\n",
        "## 2) Data Processing\n",
        "## 3) re-scale  data"
      ],
      "metadata": {
        "id": "tHw_p8Ds4Irk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import LSTM, Dense, Dropout,Bidirectional\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, LSTM\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import r2_score,mean_squared_error"
      ],
      "metadata": {
        "id": "RIZ3Xddt4dMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data sources path\n",
        "\n",
        "df1_path = (r'G:\\My Drive\\Colab Notebooks\\data\\3Feb2025.csv')\n",
        "df2_path = (r'G:\\My Drive\\Colab Notebooks\\data\\Qnum_2.csv')\n",
        "df3_path = (r'G:\\My Drive\\Colab Notebooks\\data\\merge2.csv')"
      ],
      "metadata": {
        "id": "e990Rcpq4-iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##df3 = pd.read_csv(r'md_dat.csv')\n",
        "df3 = pd.read_csv(df3_path)"
      ],
      "metadata": {
        "id": "PpKxUQJO5Lcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data normalization\n",
        "scaler=StandardScaler().fit(df3.values)\n",
        "transformed_dataset=scaler.transform(df3.values)\n",
        "transformed_df=pd.DataFrame(data=transformed_dataset, index=df3.index)"
      ],
      "metadata": {
        "id": "ruG-4cLK5CXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define hyper params of models\n",
        "number_of_rows=df3.values.shape[0]      # all variations\n",
        "window_length = 10  ## nos of previous results in consideration of prediction\n",
        "\n",
        "number_of_features=df3.values.shape[1]    # variable b' count\n",
        "print('shape = ',q2,', no_of_features   =',number_of_features,', window_length   =',window_length)"
      ],
      "metadata": {
        "id": "i3iv4exZ5ot7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## create X and y (of scaled data, formatted for keras model(rows,windows size, balls))\n",
        "\n",
        "window_length = window_length\n",
        "X = np.empty([ number_of_rows - window_length, window_length, number_of_features], dtype=float)\n",
        "y = np.empty([ number_of_rows - window_length, number_of_features], dtype=float)\n",
        "for i in range(0, number_of_rows-window_length):\n",
        "    X[i] = transformed_df.iloc[i : i+window_length, 0 : number_of_features]\n",
        "    y[i] = transformed_df.iloc[i+window_length : i+window_length+1, 0 : number_of_features]"
      ],
      "metadata": {
        "id": "qOnHOTUW5thK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## check out X,y shape:\n",
        "X.shape\n",
        "y.shape\n",
        "X[0]\n",
        "X[1]\n",
        "y[1]\n",
        "\n"
      ],
      "metadata": {
        "id": "TMaGuYvd53Qr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}